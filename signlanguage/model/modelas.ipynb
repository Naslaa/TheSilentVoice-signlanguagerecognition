{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/django/TheSilentVoice-signlanguagerecognition/signlanguage')\n",
    "from neural_network import Network\n",
    "from neural_network.layers import *\n",
    "from neural_network.activations import *\n",
    "from neural_network.optimizers import *\n",
    "from neural_network.costs import *\n",
    "from neural_network.metrics import *\n",
    "from neural_network.utils import format_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape: (69600, 100, 100)\n",
      "Train Labels shape: (69600,)\n",
      "Validation Data shape: (8700, 100, 100)\n",
      "Validation Labels shape: (8700,)\n",
      "Test Data shape: (8700, 100, 100)\n",
      "Test Labels shape: (8700,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path, image_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    categories = {\n",
    "        \"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3, \"E\": 4, \"F\": 5, \"G\": 6, \"H\": 7, \"I\": 8, \"J\": 9,\n",
    "        \"K\": 10, \"L\": 11, \"M\": 12, \"N\": 13, \"O\": 14, \"P\": 15, \"Q\": 16, \"R\": 17, \"S\": 18,\n",
    "        \"T\": 19, \"U\": 20, \"V\": 21, \"W\": 22, \"X\": 23, \"Y\": 24, \"Z\": 25, \"del\": 26,\n",
    "        \"nothing\": 27, \"space\": 28\n",
    "    }\n",
    "\n",
    "    for category, label in categories.items():\n",
    "        class_path = os.path.join(path, category)\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (image_size, image_size))\n",
    "            image = image.astype('float32') / 255.0\n",
    "            \n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "# Define the image size and paths\n",
    "image_size = 100  # Adjust this as per your requirements\n",
    "train_path = 'C:/Users/Dell/Downloads/GSASLdatasets/train/'\n",
    "val_path = 'C:/Users/Dell/Downloads/GSASLdatasets/val/'\n",
    "test_path = 'C:/Users/Dell/Downloads/GSASLdatasets/test/'\n",
    "\n",
    "# Load training, validation, and test data\n",
    "train_data, train_labels = load_data(train_path, image_size)\n",
    "val_data, val_labels = load_data(val_path, image_size)\n",
    "test_data, test_labels = load_data(test_path, image_size)\n",
    "\n",
    "# Print the shapes of the loaded data\n",
    "print(\"Train Data shape:\", train_data.shape)\n",
    "print(\"Train Labels shape:\", train_labels.shape)\n",
    "print(\"Validation Data shape:\", val_data.shape)\n",
    "print(\"Validation Labels shape:\", val_labels.shape)\n",
    "print(\"Test Data shape:\", test_data.shape)\n",
    "print(\"Test Labels shape:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for compatibility with neural network libraries\n",
    "train_data = train_data.reshape((-1, image_size, image_size, 1))  # For a grayscale image\n",
    "val_data = val_data.reshape((-1, image_size, image_size, 1))  # For a grayscale image\n",
    "test_data = test_data.reshape((-1, image_size, image_size, 1))  # For a grayscale image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    encoded_labels = np.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        encoded_labels[i][label] = 1\n",
    "    return encoded_labels\n",
    "\n",
    "num_classes = 29  # Total number of classes\n",
    "\n",
    "train_labels_one_hot = one_hot_encode(train_labels, num_classes)\n",
    "val_labels_one_hot = one_hot_encode(val_labels, num_classes)\n",
    "test_labels_one_hot = one_hot_encode(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(\n",
    "  optimizer=GradientDescentOptmizer(learning_rate=0.01),\n",
    "  cost=BinaryCrossEntropyCost(),\n",
    "  metric=CategoricalAccuracyMetric()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "network.add(InputLayer(shape=(1, 100, 100)))\n",
    "network.add(Conv2DLayer(num_of_kernels=64, kernel_shape=(3, 3), num_of_channels=1, stride=(1, 1)))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(Conv2DLayer(num_of_kernels=64, kernel_shape=(3, 3), num_of_channels=1, stride=(1, 1)))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(MaxPooling2DLayer(pool_shape=(2, 2), stride=(2, 2)))\n",
    "network.add(DropoutLayer(drop_probability=0.2))\n",
    "\n",
    "network.add(Conv2DLayer(num_of_kernels=128, kernel_shape=(3, 3), num_of_channels=1, stride=(1, 1)))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(Conv2DLayer(num_of_kernels=128, kernel_shape=(3, 3), num_of_channels=1, stride=(1, 1)))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(MaxPooling2DLayer(pool_shape=(2, 2), stride=(2, 2)))\n",
    "network.add(DropoutLayer(drop_probability=0.3))\n",
    "\n",
    "network.add(Conv2DLayer(num_of_kernels=256, kernel_shape=(3, 3), num_of_channels=1, stride=(1, 1)))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(Conv2DLayer(num_of_kernels=256, kernel_shape=(3, 3), num_of_channels=1, stride=(1, 1)))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(MaxPooling2DLayer(pool_shape=(2, 2), stride=(2, 2)))\n",
    "\n",
    "network.add(DropoutLayer(drop_probability=0.4))\n",
    "\n",
    "network.add(FlattenLayer())\n",
    "network.add(DenseLayer(units=512))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(DropoutLayer(drop_probability=0.3))\n",
    "network.add(DenseLayer(units=256))\n",
    "network.add(ActivationLayer(function=relu))\n",
    "network.add(DropoutLayer(drop_probability=0.5))\n",
    "network.add(DenseLayer(units=num_classes))\n",
    "network.add(ActivationLayer(function=softmax))\n",
    "\n",
    "# Load the network configuration\n",
    "network.load_config('config.pkl.gz')\n",
    "\n",
    "# Compile the network\n",
    "network.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\n",
      "Epoch: 1/15\t2023-12-27 14:29:06.083772\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.59 GiB for an array with shape (69600, 100, 100, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels_one_hot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\django/TheSilentVoice-signlanguagerecognition/signlanguage\\neural_network\\__init__.py:59\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[1;34m(self, train_data, epochs, batch_size, validation_data, test_data)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     58\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(generate_batches(train_data, batch_size)):\n\u001b[0;32m     61\u001b[0m   predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeedforward(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     63\u001b[0m   train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost\u001b[38;5;241m.\u001b[39mloss(predict, y)\n",
      "File \u001b[1;32mC:\\django/TheSilentVoice-signlanguagerecognition/signlanguage\\neural_network\\utils.py:24\u001b[0m, in \u001b[0;36mgenerate_batches\u001b[1;34m(data, batch_size, random)\u001b[0m\n\u001b[0;32m     22\u001b[0m   n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(N)\n\u001b[0;32m     23\u001b[0m   np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(n)\n\u001b[1;32m---> 24\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m, y[n]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, N, batch_size):\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     x[i:\u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m batch_size, N)],\n\u001b[0;32m     29\u001b[0m     y[i:\u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m batch_size, N)]\n\u001b[0;32m     30\u001b[0m   )\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.59 GiB for an array with shape (69600, 100, 100, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "network.fit(\n",
    "    train_data=(train_data, train_labels_one_hot),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_data=(val_data, val_labels_one_hot),\n",
    "    test_data=(test_data, test_labels_one_hot)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
