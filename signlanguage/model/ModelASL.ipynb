{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/Users/Dell/Downloads/GSASLdatasets/train/\"\n",
    "categories = {0: \"A\",\n",
    "                1: \"B\",\n",
    "                2: \"C\",\n",
    "                3: \"D\",\n",
    "                4: \"E\",\n",
    "                5: \"F\",\n",
    "                6: \"G\",\n",
    "                7: \"H\",\n",
    "                8: \"I\",\n",
    "                9: \"J\",\n",
    "                10: \"K\",\n",
    "                11: \"L\",\n",
    "                12: \"M\",\n",
    "                13: \"N\",\n",
    "                14: \"O\",\n",
    "                15: \"P\",\n",
    "                16: \"Q\",\n",
    "                17: \"R\",\n",
    "                18: \"S\",\n",
    "                19: \"T\",\n",
    "                20: \"U\",\n",
    "                21: \"V\",\n",
    "                22: \"W\",\n",
    "                23: \"X\",\n",
    "                24: \"Y\",\n",
    "                25: \"Z\",\n",
    "                26: \"del\",\n",
    "                27: \"nothing\",\n",
    "                28: \"space\",\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess images\n",
    "def preprocess_image(path, image_size):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (image_size, image_size))\n",
    "    img = img.astype('float32') / 255.0  # Normalization\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your dataset folders\n",
    "train_path = \"C:/Users/Dell/Downloads/GSASLdatasets/train/\"\n",
    "val_path = \"C:/Users/Dell/Downloads/GSASLdatasets/val/\"\n",
    "test_path = \"C:/Users/Dell/Downloads/GSASLdatasets/test/\"\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "    categories = os.listdir(folder)\n",
    "    for category in categories:\n",
    "        label = categories.index(category)  # Assigning labels based on folder names\n",
    "        category_path = os.path.join(folder, category)\n",
    "        for filename in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, filename)\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (100, 100))\n",
    "            image = image.astype('float32') / 255.0  # Normalization\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Load train, validation, and test datasets\n",
    "train_data, train_labels = load_images_from_folder(train_path)\n",
    "val_data, val_labels = load_images_from_folder(val_path)\n",
    "test_data, test_labels = load_images_from_folder(test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, num_filters, filter_size):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / (filter_size * filter_size)\n",
    "        self.bias = np.zeros((num_filters, 1))\n",
    "    \n",
    "    def iterate_regions(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            h, w, _ = image.shape  # Get height, width, and channels\n",
    "        elif len(image.shape) == 2:\n",
    "            h, w = image.shape  # Assume single-channel image\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected input shape\")\n",
    "\n",
    "        for i in range(h - self.filter_size + 1):\n",
    "            for j in range(w - self.filter_size + 1):\n",
    "                if len(image.shape) == 3:\n",
    "                    im_region = image[i:(i + self.filter_size), j:(j + self.filter_size), :]\n",
    "                else:\n",
    "                    im_region = image[i:(i + self.filter_size), j:(j + self.filter_size)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        if len(input.shape) == 2:\n",
    "            input = np.expand_dims(input, axis=-1)  # Add the channel dimension\n",
    "            h, w, _ = input.shape\n",
    "        elif len(input.shape) == 3:\n",
    "            h, w, _ = input.shape\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected input shape\")\n",
    "\n",
    "        output_h = h - self.filter_size + 1\n",
    "        output_w = w - self.filter_size + 1\n",
    "        output = np.zeros((output_h, output_w, self.num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            for f in range(self.num_filters):\n",
    "                # Ensure compatibility by expanding the dimensions\n",
    "                expanded_filter = np.expand_dims(self.filters[f, :, :], axis=-1)\n",
    "                # Perform element-wise multiplication and sum along the channels\n",
    "                output[i, j, f] = np.sum(im_region * expanded_filter) + self.bias[f]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, filter_size):\n",
    "        self.filter_size = filter_size\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        h, w, num_filters = image.shape\n",
    "        new_h = h // self.filter_size\n",
    "        new_w = w // self.filter_size\n",
    "\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = image[(i * self.filter_size):(i * self.filter_size + self.filter_size),\n",
    "                                  (j * self.filter_size):(j * self.filter_size + self.filter_size), :]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        h, w, num_filters = input.shape\n",
    "        output_h = h // self.filter_size\n",
    "        output_w = w // self.filter_size\n",
    "        output = np.zeros((output_h, output_w, num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            for f in range(num_filters):\n",
    "                output[i, j, f] = np.amax(im_region[:, :, f])\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "class Dense:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2.0 / input_size)\n",
    "        self.biases = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        if len(input.shape) != 1:\n",
    "            input = input.reshape(-1, 1)  # Reshape the input to match the expected shape\n",
    "        output = np.dot(input.T, self.weights) + self.biases  # Perform dot product\n",
    "        return output\n",
    "    \n",
    "    def backward(self, gradients):\n",
    "        # Calculate gradients with respect to the layer's input\n",
    "        input_gradients = np.dot(gradients, self.weights.T)\n",
    "\n",
    "        # Update weights and biases using gradients (for learning purposes)\n",
    "        weights_gradients = np.dot(self.last_input.T, gradients)\n",
    "        biases_gradients = gradients.mean(axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights -= learning_rate * weights_gradients\n",
    "        self.biases -= learning_rate * biases_gradients\n",
    "\n",
    "        return input_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.maximum(0, input)\n",
    "    \n",
    "    def backward(self, gradients):\n",
    "        return gradients.reshape(self.input.shape) * (self.input > 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture\n",
    "conv1 = Conv2D(num_filters=64, filter_size=3)\n",
    "pool1 = MaxPool2D(filter_size=2)\n",
    "conv2 = Conv2D(num_filters=128, filter_size=3)\n",
    "pool2 = MaxPool2D(filter_size=2)\n",
    "dense1 = Dense(67712, 512)  \n",
    "dense2 = Dense(512, 29)  # Assuming num_classes is defined\n",
    "relu = ReLU()\n",
    "\n",
    "# Define forward pass\n",
    "def forward(image, label):\n",
    "    out = conv1.forward(image)\n",
    "    out = relu.forward(out)\n",
    "    out = pool1.forward(out)\n",
    "    \n",
    "    out = conv2.forward(out)\n",
    "    out = relu.forward(out)\n",
    "    out = pool2.forward(out)\n",
    "    \n",
    "    # Flatten the output from the convolutional layers\n",
    "    flattened = out.reshape(-1)\n",
    "    \n",
    "    out = dense1.forward(flattened)\n",
    "    out = relu.forward(out)\n",
    "    out = dense2.forward(out)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = (out - label) ** 2\n",
    "    \n",
    "    return out, loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (29,512) and (29,1) not aligned: 512 (dim 1) != 29 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m dense2_gradients \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (out \u001b[38;5;241m-\u001b[39m label)\n\u001b[0;32m     16\u001b[0m dense2_input_gradients \u001b[38;5;241m=\u001b[39m dense2\u001b[38;5;241m.\u001b[39mbackward(dense2_gradients)\n\u001b[1;32m---> 18\u001b[0m dense1_gradients \u001b[38;5;241m=\u001b[39m \u001b[43mdense2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdense2_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     19\u001b[0m dense1_input_gradients \u001b[38;5;241m=\u001b[39m relu\u001b[38;5;241m.\u001b[39mbackward(dense1\u001b[38;5;241m.\u001b[39mlast_input) \u001b[38;5;241m*\u001b[39m dense1_gradients\n\u001b[0;32m     21\u001b[0m dense2\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(dense1\u001b[38;5;241m.\u001b[39mlast_input, dense2_gradients)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (29,512) and (29,1) not aligned: 512 (dim 1) != 29 (dim 0)"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    # Training\n",
    "    for i, image in enumerate(train_data):\n",
    "        label = train_labels[i]\n",
    "        \n",
    "        # Forward pass\n",
    "        out, loss = forward(image, label)\n",
    "\n",
    "        # Backward pass\n",
    "        dense2_gradients = 2 * (out - label)\n",
    "        dense2_input_gradients = dense2.backward(dense2_gradients)\n",
    "        \n",
    "        dense1_gradients = dense2.weights.T.dot(dense2_gradients.T).T\n",
    "        dense1_input_gradients = relu.backward(dense1.last_input) * dense1_gradients\n",
    "        \n",
    "        dense2.weights -= learning_rate * np.outer(dense1.last_input, dense2_gradients)\n",
    "        dense1.weights -= learning_rate * np.outer(flattened, dense1_input_gradients)\n",
    "        \n",
    "        dense1_input_gradients = dense1.backward(dense1.last_input)\n",
    "        \n",
    "        pool2_input_gradients = dense1_input_gradients.reshape(pool2_out.shape)\n",
    "        conv2_input_gradients = pool2.backward(pool2_input_gradients)\n",
    "        \n",
    "        pool1_input_gradients = conv2_input_gradients\n",
    "        conv1_input_gradients = pool1.backward(pool1_input_gradients)\n",
    "        \n",
    "        # Update weights for convolutional layers\n",
    "        conv2.filters -= learning_rate * conv2_input_gradients\n",
    "        conv1.filters -= learning_rate * conv1_input_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
